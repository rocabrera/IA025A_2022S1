{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rocabrera/IA025A_2022S1/blob/master/ex05/Aula_5_Exercicio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdORg7oe68oq",
    "outputId": "9f44d5fb-147c-43aa-8115-dc6a30c04b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu nome é Rodrigo Cabrera Castaldoni\n"
     ]
    }
   ],
   "source": [
    "nome = \"Rodrigo Cabrera Castaldoni\"\n",
    "print(f'Meu nome é {nome}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkfGTqMVQT1u"
   },
   "source": [
    "Este exercicío consiste em treinar no MNIST um modelo de umas camadas, sendo a primeira uma camada convolucional e a segunda uma camada linear de classificação.\n",
    "\n",
    "Não podemos usar as funções torch.nn.Conv{1,2,3}d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFNf4RPxQT1w"
   },
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T14:08:14.033692Z",
     "start_time": "2018-08-21T14:08:11.179981Z"
    },
    "id": "-fLUSHaCQT1x"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_Po22b5ykhK"
   },
   "source": [
    "## Fixando as seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-7WWWgLyoRq",
    "outputId": "b57b287d-1ad0-4662-9cf5-6dbd71b706fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1eac28a810>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzurMVpHxcNG"
   },
   "source": [
    "## Define pesos iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9a6jQJLLlfF3"
   },
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "out_channels = 2\n",
    "kernel_size = 5\n",
    "stride = 3\n",
    "\n",
    "# Input image size\n",
    "height_in = 28  \n",
    "width_in = 28\n",
    "\n",
    "# Image size after the first convolutional layer.\n",
    "height_out = (height_in - kernel_size) // stride + 1\n",
    "width_out = (width_in - kernel_size) // stride + 1\n",
    "\n",
    "initial_conv_weight = torch.FloatTensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01)\n",
    "initial_conv_bias = torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01)\n",
    "\n",
    "initial_classification_weight = torch.FloatTensor(10, out_channels * height_out * width_out).uniform_(-0.01, 0.01)\n",
    "initial_classification_bias = torch.FloatTensor(10,).uniform_(-0.01, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEMUsfJpQT11"
   },
   "source": [
    "## Dataset e dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHoQjDs_QT12"
   },
   "source": [
    "### Definição do tamanho do minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T14:08:20.282474Z",
     "start_time": "2018-08-21T14:08:20.275450Z"
    },
    "id": "tEQYUr4TQT13"
   },
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc7Rv_2BQT16"
   },
   "source": [
    "### Carregamento, criação dataset e do dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T14:10:45.430605Z",
     "start_time": "2018-08-21T14:10:04.953051Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0dEKCn-QT17",
    "outputId": "10d3f0f4-0258-4fb6-f39f-66f1e841d873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '../data/'\n",
    "\n",
    "dataset_train_full = MNIST(dataset_dir, train=True, download=True,\n",
    "                           transform=torchvision.transforms.ToTensor())\n",
    "print(dataset_train_full.data.shape)\n",
    "print(dataset_train_full.targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rOy9ntrQT2D"
   },
   "source": [
    "### Usando apenas 1000 amostras do MNIST\n",
    "\n",
    "Neste exercício utilizaremos 1000 amostras de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WNF2XjLBWWe7"
   },
   "outputs": [],
   "source": [
    "indices = torch.randperm(len(dataset_train_full))[:1000]\n",
    "dataset_train = torch.utils.data.Subset(dataset_train_full, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYqj_oeSliYj"
   },
   "source": [
    "## Define os pesos iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aSNLD2JyA2e-"
   },
   "outputs": [],
   "source": [
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T13:30:35.209157Z",
     "start_time": "2018-08-21T13:30:34.757103Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w52KGYlIQT2A",
    "outputId": "1643fe03-a4be-486f-81fb-f94a99269c35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de minibatches de trenamento: 20\n",
      "\n",
      "Dimensões dos dados de um minibatch: torch.Size([50, 1, 28, 28])\n",
      "Valores mínimo e máximo dos pixels:  tensor(0.) tensor(1.)\n",
      "Tipo dos dados das imagens:          <class 'torch.Tensor'>\n",
      "Tipo das classes das imagens:        <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print('Número de minibatches de trenamento:', len(loader_train))\n",
    "\n",
    "x_train, y_train = next(iter(loader_train))\n",
    "print(\"\\nDimensões dos dados de um minibatch:\", x_train.size())\n",
    "print(\"Valores mínimo e máximo dos pixels: \", torch.min(x_train), torch.max(x_train))\n",
    "print(\"Tipo dos dados das imagens:         \", type(x_train))\n",
    "print(\"Tipo das classes das imagens:       \", type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfU_v7aPfq40"
   },
   "source": [
    "## Camada Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wRtpLJSFfsf8"
   },
   "outputs": [],
   "source": [
    "class MyConv2d(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
    "        super(MyConv2d, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size  # The same for height and width.\n",
    "        self.stride = stride  # The same for height and width.\n",
    "        self.weight = torch.nn.Parameter(torch.FloatTensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01))\n",
    "        self.bias = torch.nn.Parameter(torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.dim() == 4, f'x must have 4 dimensions: {x.shape}'\n",
    "        # Escreva seu código aqui.\n",
    "        batch_size, channels, h_in, w_in = x.shape        \n",
    "        h_out = (h_in - self.kernel_size) // self.stride + 1\n",
    "\n",
    "        w_out = (w_in - self.kernel_size) // self.stride + 1\n",
    "        \n",
    "        out = torch.zeros((batch_size, self.out_channels, h_out, w_out))\n",
    "        \n",
    "        # Toda convolução começa no canto superior esquerdo\n",
    "        imin, imax, jmin, jmax = 0, self.kernel_size, 0, self.kernel_size\n",
    "        for n_channel in range(self.out_channels):\n",
    "            for i in range(h_out):\n",
    "                for j in range(w_out):\n",
    "                    i_step = self.stride*i\n",
    "                    j_step = self.stride*j\n",
    "                    window = x[:, :, (imin + i_step):(imax + i_step), (jmin + j_step):(jmax + j_step)]\n",
    "                    out[:, n_channel, i, j] = torch.sum(window * self.weight[n_channel], dim=(1,2,3)) + self.bias[n_channel] \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROizI33sqE79"
   },
   "source": [
    "## Compare se sua implementação está igual à do pytorch usando um exemplo simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "i1TuxWbkqMJc"
   },
   "outputs": [],
   "source": [
    "in_channels_dummy = 1\n",
    "out_channels_dummy = 1\n",
    "kernel_size_dummy = 2\n",
    "stride_dummy = 1\n",
    "\n",
    "conv_layer = MyConv2d(in_channels=in_channels_dummy, out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy)\n",
    "pytorch_conv_layer = torch.nn.Conv2d(in_channels=in_channels_dummy, out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, padding=0)\n",
    "\n",
    "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
    "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
    "initial_weights_dummy = initial_weights_dummy.reshape(out_channels_dummy, in_channels_dummy, kernel_size_dummy, kernel_size_dummy)\n",
    "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
    "\n",
    "conv_layer.weight.data = initial_weights_dummy\n",
    "conv_layer.bias.data = initial_bias_dummy\n",
    "pytorch_conv_layer.load_state_dict(dict(weight=initial_weights_dummy, bias=initial_bias_dummy))\n",
    "\n",
    "x = torch.arange(30).float().reshape(1, 1, 5, 6)\n",
    "\n",
    "out = conv_layer(x)\n",
    "target_out = pytorch_conv_layer(x)\n",
    "\n",
    "assert torch.allclose(out, target_out, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_75UnRhdd_MW"
   },
   "source": [
    "## Compare se sua implementação está igual à do pytorch usando um exemplo aleatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HzIjuGpWlbIM"
   },
   "outputs": [],
   "source": [
    "x = torch.rand(2, in_channels, height_in, width_in)\n",
    "\n",
    "conv_layer = MyConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "pytorch_conv_layer = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
    "conv_layer.weight.data = initial_conv_weight\n",
    "conv_layer.bias.data = initial_conv_bias\n",
    "pytorch_conv_layer.load_state_dict(dict(weight=initial_conv_weight, bias=initial_conv_bias))\n",
    "\n",
    "out = conv_layer(x)\n",
    "target_out = pytorch_conv_layer(x)\n",
    "\n",
    "assert torch.allclose(out, target_out, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQA9Zg7GQT2G"
   },
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:03:10.802708Z",
     "start_time": "2018-08-20T21:03:10.793287Z"
    },
    "id": "_8Eg4h_kQT2H"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, height_in: int, width_in: int, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layer = MyConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "   \n",
    "        height_out = (height_in - kernel_size) // stride + 1\n",
    "        width_out = (width_in - kernel_size) // stride + 1\n",
    "        self.classification_layer = torch.nn.Linear(out_channels * height_out * width_out, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.conv_layer(x)\n",
    "        hidden = torch.nn.functional.relu(hidden)\n",
    "        hidden = hidden.reshape(x.shape[0], -1)\n",
    "        logits = self.classification_layer(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NHQB4wGQT2K"
   },
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqs2JhJoQT2L"
   },
   "source": [
    "### Definição dos hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:03:14.146259Z",
     "start_time": "2018-08-20T21:03:14.139515Z"
    },
    "id": "oZuYEkn_QT2M"
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmXarXeIQT2O"
   },
   "source": [
    "### Laço de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:03:40.796410Z",
     "start_time": "2018-08-20T21:03:39.771981Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5T_jZZPQT2P",
    "outputId": "841fe811-9fd2-4639-a863-548c11487ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/49 Loss: 2.303267478942871\n",
      "Epoch: 1/49 Loss: 2.227701187133789\n",
      "Epoch: 2/49 Loss: 1.0923893451690674\n",
      "Epoch: 3/49 Loss: 0.5867355465888977\n",
      "Epoch: 4/49 Loss: 0.5144088864326477\n",
      "Epoch: 5/49 Loss: 0.4502663016319275\n",
      "Epoch: 6/49 Loss: 0.4075140357017517\n",
      "Epoch: 7/49 Loss: 0.37713873386383057\n",
      "Epoch: 8/49 Loss: 0.35344862937927246\n",
      "Epoch: 9/49 Loss: 0.3341451585292816\n",
      "Epoch: 10/49 Loss: 0.3181139826774597\n",
      "Epoch: 11/49 Loss: 0.30457887053489685\n",
      "Epoch: 12/49 Loss: 0.292834997177124\n",
      "Epoch: 13/49 Loss: 0.28276076912879944\n",
      "Epoch: 14/49 Loss: 0.27383318543434143\n",
      "Epoch: 15/49 Loss: 0.2657742202281952\n",
      "Epoch: 16/49 Loss: 0.2583288252353668\n",
      "Epoch: 17/49 Loss: 0.2511751055717468\n",
      "Epoch: 18/49 Loss: 0.24439717829227448\n",
      "Epoch: 19/49 Loss: 0.23789966106414795\n",
      "Epoch: 20/49 Loss: 0.2316770702600479\n",
      "Epoch: 21/49 Loss: 0.22562645375728607\n",
      "Epoch: 22/49 Loss: 0.21984529495239258\n",
      "Epoch: 23/49 Loss: 0.2142912745475769\n",
      "Epoch: 24/49 Loss: 0.2089422196149826\n",
      "Epoch: 25/49 Loss: 0.203872948884964\n",
      "Epoch: 26/49 Loss: 0.19903425872325897\n",
      "Epoch: 27/49 Loss: 0.1943996250629425\n",
      "Epoch: 28/49 Loss: 0.18994112312793732\n",
      "Epoch: 29/49 Loss: 0.1856399029493332\n",
      "Epoch: 30/49 Loss: 0.18147501349449158\n",
      "Epoch: 31/49 Loss: 0.17744922637939453\n",
      "Epoch: 32/49 Loss: 0.17347262799739838\n",
      "Epoch: 33/49 Loss: 0.1694747358560562\n",
      "Epoch: 34/49 Loss: 0.16547317802906036\n",
      "Epoch: 35/49 Loss: 0.16150495409965515\n",
      "Epoch: 36/49 Loss: 0.15746407210826874\n",
      "Epoch: 37/49 Loss: 0.1534043401479721\n",
      "Epoch: 38/49 Loss: 0.14926917850971222\n",
      "Epoch: 39/49 Loss: 0.14520631730556488\n",
      "Epoch: 40/49 Loss: 0.14123666286468506\n",
      "Epoch: 41/49 Loss: 0.1371268630027771\n",
      "Epoch: 42/49 Loss: 0.1331036537885666\n",
      "Epoch: 43/49 Loss: 0.12914671003818512\n",
      "Epoch: 44/49 Loss: 0.125150665640831\n",
      "Epoch: 45/49 Loss: 0.12116766721010208\n",
      "Epoch: 46/49 Loss: 0.11731737107038498\n",
      "Epoch: 47/49 Loss: 0.1136462464928627\n",
      "Epoch: 48/49 Loss: 0.1100190058350563\n",
      "Epoch: 49/49 Loss: 0.10655996203422546\n"
     ]
    }
   ],
   "source": [
    "model = Net(height_in=height_in, width_in=width_in, in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "\n",
    "# Usa pesos iniciais pré-difinidos\n",
    "model.classification_layer.load_state_dict(dict(weight=initial_classification_weight, bias=initial_classification_bias))\n",
    "model.conv_layer.weight.data = initial_conv_weight\n",
    "model.conv_layer.bias.data = initial_conv_bias\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "\n",
    "epochs = []\n",
    "loss_history = []\n",
    "loss_epoch_end = []\n",
    "total_trained_samples = 0\n",
    "for i in range(n_epochs):\n",
    "    for x_train, y_train in loader_train:\n",
    "        # predict da rede\n",
    "        outputs = model(x_train)\n",
    "\n",
    "        # calcula a perda\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_trained_samples += x_train.size(0)\n",
    "        epochs.append(total_trained_samples / len(dataset_train))\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "    loss_epoch_end.append(loss.item())\n",
    "    print(f'Epoch: {i:d}/{n_epochs - 1:d} Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLL-GQlKQT2Y"
   },
   "source": [
    "### Visualização usual da perda, somente no final de cada minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:03:55.246851Z",
     "start_time": "2018-08-20T21:03:54.994428Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "w38EtNxhQT2Z",
    "outputId": "c2014ba6-e541-4259-d1e8-6c31a93af9e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'época')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_batches_train = len(loader_train)\n",
    "plt.plot(epochs[::n_batches_train], loss_history[::n_batches_train])\n",
    "plt.xlabel('época')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ToktJu4CK94z",
    "outputId": "7ca3549c-5fe4-4b83-adf8-3fbf1750f13d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.303267478942871,\n",
       " 2.227701187133789,\n",
       " 1.0923893451690674,\n",
       " 0.5867355465888977,\n",
       " 0.5144088864326477,\n",
       " 0.4502663016319275,\n",
       " 0.4075140357017517,\n",
       " 0.37713873386383057,\n",
       " 0.35344862937927246,\n",
       " 0.3341451585292816,\n",
       " 0.3181139826774597,\n",
       " 0.30457887053489685,\n",
       " 0.292834997177124,\n",
       " 0.28276076912879944,\n",
       " 0.27383318543434143,\n",
       " 0.2657742202281952,\n",
       " 0.2583288252353668,\n",
       " 0.2511751055717468,\n",
       " 0.24439717829227448,\n",
       " 0.23789966106414795,\n",
       " 0.2316770702600479,\n",
       " 0.22562645375728607,\n",
       " 0.21984529495239258,\n",
       " 0.2142912745475769,\n",
       " 0.2089422196149826,\n",
       " 0.203872948884964,\n",
       " 0.19903425872325897,\n",
       " 0.1943996250629425,\n",
       " 0.18994112312793732,\n",
       " 0.1856399029493332,\n",
       " 0.18147501349449158,\n",
       " 0.17744922637939453,\n",
       " 0.17347262799739838,\n",
       " 0.1694747358560562,\n",
       " 0.16547317802906036,\n",
       " 0.16150495409965515,\n",
       " 0.15746407210826874,\n",
       " 0.1534043401479721,\n",
       " 0.14926917850971222,\n",
       " 0.14520631730556488,\n",
       " 0.14123666286468506,\n",
       " 0.1371268630027771,\n",
       " 0.1331036537885666,\n",
       " 0.12914671003818512,\n",
       " 0.125150665640831,\n",
       " 0.12116766721010208,\n",
       " 0.11731737107038498,\n",
       " 0.1136462464928627,\n",
       " 0.1100190058350563,\n",
       " 0.10655996203422546]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_epoch_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:03:48.786969Z",
     "start_time": "2018-08-20T21:03:48.781787Z"
    },
    "id": "PiuMsjYtQT2R"
   },
   "outputs": [],
   "source": [
    "# Assert do histórico de losses\n",
    "target_loss_epoch_end = np.array([\n",
    "    2.303267478942871,\n",
    "    2.227701187133789,\n",
    "    1.0923893451690674,\n",
    "    0.5867354869842529,\n",
    "    0.5144089460372925,\n",
    "    0.45026642084121704,\n",
    "    0.4075140357017517,\n",
    "    0.37713879346847534,\n",
    "    0.3534485101699829,\n",
    "    0.3341451585292816,\n",
    "    0.3181140422821045,\n",
    "    0.30457887053489685,\n",
    "    0.29283496737480164,\n",
    "    0.2827608287334442,\n",
    "    0.2738332152366638,\n",
    "    0.2657742500305176,\n",
    "    0.2583288848400116,\n",
    "    0.25117507576942444,\n",
    "    0.24439716339111328,\n",
    "    0.23789969086647034,\n",
    "    0.23167723417282104,\n",
    "    0.22562651336193085,\n",
    "    0.21984536945819855,\n",
    "    0.2142913043498993,\n",
    "    0.20894232392311096,\n",
    "    0.203872948884964,\n",
    "    0.19903430342674255,\n",
    "    0.19439971446990967,\n",
    "    0.18994088470935822,\n",
    "    0.18563991785049438,\n",
    "    0.18147490918636322,\n",
    "    0.17744913697242737,\n",
    "    0.17347246408462524,\n",
    "    0.16947467625141144,\n",
    "    0.16547319293022156,\n",
    "    0.16150487959384918,\n",
    "    0.1574639081954956,\n",
    "    0.1534043848514557,\n",
    "    0.14926929771900177,\n",
    "    0.1452063024044037,\n",
    "    0.1412365883588791,\n",
    "    0.13712672889232635,\n",
    "    0.1331038922071457,\n",
    "    0.1291467249393463,\n",
    "    0.1251506358385086,\n",
    "    0.12116757035255432,\n",
    "    0.11731722950935364,\n",
    "    0.11364627629518509,\n",
    "    0.11001908034086227,\n",
    "    0.10655981302261353])\n",
    "\n",
    "assert np.allclose(np.array(loss_epoch_end), target_loss_epoch_end, atol=1e-6)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Aula 5 - Exercicio",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "nav_menu": {
    "height": "318px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
